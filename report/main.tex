\documentclass[letter, 11pt, margin=1in]{article}
\usepackage{comment} % enables the use of multi-line comments (\ifx \fi) 
\usepackage{fullpage} % changes the margin
\usepackage{xcolor}
\usepackage{amsmath}
\usepackage[T1]{fontenc}
\usepackage{inconsolata}
\usepackage{geometry}
 \geometry{
 a4paper,
 total={170mm,257mm},
 left=10mm,
 right=10mm,
 top=20mm,
 }

\usepackage{color}

\definecolor{pblue}{rgb}{0.13,0.13,1}
\definecolor{pgreen}{rgb}{0,0.5,0}
\definecolor{pred}{rgb}{0.9,0,0}
\definecolor{pgrey}{rgb}{0.46,0.45,0.48}
\usepackage{listings}
\lstset{language=Java,
  showspaces=false,
  showtabs=false,
  breaklines=true,
  showstringspaces=false,
  breakatwhitespace=true,
  commentstyle=\color{pgreen},
  keywordstyle=\color{pblue},
  stringstyle=\color{pred},
  basicstyle=\ttfamily,
  moredelim=[il][\textcolor{pgrey}]{$$},
  moredelim=[is][\textcolor{pgrey}]{\%\%}{\%\%}
}

\usepackage{graphics}
\usepackage{graphicx}
\usepackage[colorlinks = true,
            linkcolor = blue,
            urlcolor  = blue,
            citecolor = blue,
            anchorcolor = blue]{hyperref}
\usepackage[toc,page]{appendix}
\usepackage{pgfplots}
\pgfplotsset{compat=1.14}
\graphicspath{ {images/} }

\begin{document}
\noindent
\large\textbf{Introduction to Parallel and Distributed Programming} \hfill \textbf{Shreshth Tuli} \\
\normalsize COL380 - Lab Assignment 1 \hfill 2016CS10680\\
Supervisor - Prof. Subodh Sharma \hfill Date: 7/02/2019 \\

\section*{Introduction}

The K-Means clustering algorithm partitions an unlabelled set of points into \textit{k} groups. The goal of the algorithm is to minimise $\sum_{i=1}^k\frac{1}{S_i}\sum_{x,y\in S_i}||x-y||^2$. To achieve this an iterative algorithm is used where we first initialize means and then in each iteration update points and means. In this assignment serial and parallel implementations were developed and tested for different problem sizes and number of threads. Four parallelisation strategies were used:
\begin{enumerate}
    \item pThread based parallelisation where the \textit{cluster update} was parallelised referred as \textbf{pThread}
    \item pThread based parallelisation where both \textit{cluster update} and \textit{means update} were parallelised, referred as \textbf{pThread2}
    \item OpenMP based parallelisation using compiler directives, referred as \textbf{omp}
\end{enumerate}
We refer to the sequential implementation as \textbf{seq}.

\section{Implementation}
We now present various implementation details, design decisions and optimization strategies used in different implementations.

\subsection{Sequential}

\begin{itemize}
    \item Each cluster (1 to k) was given a \textit{clusterID} and goal of the algorithm was to provide the best clusterID's to all points
    \item The code was divided into two main functions for updating clusterID's of all points and updating the position of the k means.
    \item The means were initialized using a deterministic algorithm of selecting first k points as means.
    \item In a loop both update clusterID and update means' position was called successively. The loop terminated after a specific number of iterations to maintain homogeneity in the execution time across different runs of the code and easier comparison.
\end{itemize}

\subsection{pThread}

\begin{itemize}
    \item In the first level of pThread based parallelisation, the updating clusterID's was multi-threaded.
    \item All the points were partitioned into equal size sets where the number of such sets was equal to the number of threads.
    \item Each thread evaluates for it's set of points, the closest mean and updates the clusterID's
    \item To prevent thread creation overhead at each iteration the threads were created only once at the start of the program and a \textit{work\_done[]} shared array of booleans was maintained to propagate messages to and from threads when the clusterIDs need to be updated.
    \item In each iteration, in the main loop, we set \textit{work\_done[j]} to \textit{false} for all threads \textit{j}. Once this is done, the threads are indicated to update clusterIDs. The functions set their shared variable \textit{work\_done[tid]} corresponding to their thread ID : \textit{tid}.
    \item To wait for the threads to complete their work, we check continuously in the main loop if all \textit{work\_done[j]} have been set to \textit{true}. If any one of them is \textit{false} we conitnue to wait.
    \item As their is one writer of \textit{false} (the main loop) and one writer of \textit{true} (the function) for a shared variable \textit{work\_done[j]} the property of mutual exclusion holds.
\end{itemize}

\subsection{pThread2}

\begin{itemize}
    \item Like in the earlier implementation here too the function of updating the clusterIDs has been multi-threaded, but the updating means function too has been multi-threaded.
    \item To prevent too much locking and synchronization in the update mean function, a similar \textit{work\_done2[]} array has been declared.
    \item As the finding clusterIDs and updating means need to be done sequentially as they can not be overlapped, the same threads perform both jobs one after the other.
    \item Due to high overhead of so much synchronization across threads and k ranging between 2 to 10 which means k << n  for small size data this strategy performs really poorly compared to the \textbf{pThread} implementation.
\end{itemize}

\subsection{OpenMP}

\begin{itemize}
    \item For the OpenMP implementation we have used the compiler directive of \textit{#pragma omp parallel for}. This has been used in both updating clusterIDs and updating means.
    \item As we shall see later, due to optimized implementation this works slightly faster that the \textbf{pThread} approach.
    \item To prevent over writing of values \textit{shared() and private()} have been used to distinguish between shared and local variables.
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=6.2cm,height=5.5cm]{k2}
    \includegraphics[width=6.2cm,height=5.5cm]{k5}
    \includegraphics[width=6.2cm,height=5.5cm]{k10}\\
    \includegraphics[width=6.2cm,height=5.5cm]{tk2}
    \includegraphics[width=6.2cm,height=5.5cm]{tk5}
    \includegraphics[width=6.2cm,height=5.5cm]{tk10}
    \caption{Graphs showing time taken by different implementations for different k}
    \label{fig:time}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=6.2cm,height=5.5cm]{sk2}
    \includegraphics[width=6.2cm,height=5.5cm]{sk5}
    \includegraphics[width=6.2cm,height=5.5cm]{sk10}\\
    \includegraphics[width=6.2cm,height=5.5cm]{tsk2}
    \includegraphics[width=6.2cm,height=5.5cm]{tsk5}
    \includegraphics[width=6.2cm,height=5.5cm]{tsk10}
    \caption{Graphs showing Speedup of different implementations for different k}
    \label{fig:speedup}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=6.2cm,height=5.5cm]{ek2}
    \includegraphics[width=6.2cm,height=5.5cm]{ek5}
    \includegraphics[width=6.2cm,height=5.5cm]{ek10}\\
    \includegraphics[width=6.2cm,height=5.5cm]{tek2}
    \includegraphics[width=6.2cm,height=5.5cm]{tek5}
    \includegraphics[width=6.2cm,height=5.5cm]{tek10}
    \caption{Graphs showing Efficiency of different implementations for different k}
    \label{fig:efficiency}
\end{figure}

\section{Experiments}

To test the impact and efficiency of parallelisation in all the approaches we performed tests/experiments on the completion time of each implementation.

\subsection{Test setup}
The tests were run on the following setup:
\begin{itemize}
    \item Intel i7 7700K quad core processor hyper threaded to 8 virtual cores
    \item Cache line size = 64 Bytes
    \item Level 1 cache = 4 x 32 KB 8-way set associative instruction caches, 4 x 32 KB 8-way set associative data caches
    \item Level 2 cache = 4 x 256 KB 4-way set associative caches
    \item Level 3 cache = 8 MB 16-way set associative shared cache
\end{itemize}

\subsection{Observations and results}

The graphs in Figure \ref{fig:time} - \ref{fig:efficiency} show the comparison between times of different parallelized implementations. We can conclude the following:

\begin{itemize}
    \item We first observe that all execution times grow linearly with problem size = number of data points.
    \item The execution time also increases as the number of cluster = K increases.
    \item We also see that the speedup in both pThread case is higher for 4 threads $\approx$ 2.5 for k = 2 and $\approx$ 1.7 for two threads for k = 2. As k increases, the speedup also increases.
    \item Efficiency decreases as number of threads increases which is reasonable from theory as well. With problem size, efficiency remain nearly constant. So for fraction f of code be serial: \\
    \begin{align*}
        Efficiency\ &=\ \frac{T_{seq}}{p\ \times\ T_p}\\
        &= \frac{O(n)}{p \times O(fn + \frac{(1-f)n}{p})}\\
        &= O(\frac{1}{p})
    \end{align*}
    \item We see that even efficiency increases as k increases.
\end{itemize}

\begin{table}[h]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
        Factor increases & Time & Speedup & Efficiency  \\ \hline \hline
        Problem size  & $\uparrow$ & = & = \\ \hline
        k & $\uparrow$ & $\uparrow$ & $\uparrow$ \\ \hline
        Number of threads & $\downarrow$ & $\uparrow$ & $\downarrow$ \\ \hline
    \end{tabular}
    \caption{Summary of observations}
    \label{tab:my_label}
\end{table}






\end{document}
